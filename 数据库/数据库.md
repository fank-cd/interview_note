# 数据库


1、简述乐观锁以及悲观锁的区别以及使用场景
  * 乐观锁和悲观锁其实都是并发控制的机制，同时它们在原理上就有着本质的差别；
    * 乐观锁是一种思想，它其实并不是一种真正的『锁』，它会先尝试对资源进行修改，在写回时判断资源是否进行了改变，如果没有发生改变就会写回，否则就会进行重试，在整个的执行过程中其实都没有对数据库进行加锁；
    * 悲观锁就是一种真正的锁了，它会在获取资源前对资源进行加锁，确保同一时刻只有有限的线程能够访问该资源，其他想要尝试获取资源的操作都会进入等待状态，直到该线程完成了对资源的操作并且释放了锁后，其他线程才能重新操作资源；
  * 乐观锁不会存在死锁的问题，但是由于更新后验证，所以当冲突频率和重试成本较高时更推荐使用悲观锁
  * 而需要非常高的响应速度并且并发量非常大的时候使用乐观锁就能较好的解决问题，在这时使用悲观锁就可能出现严重的性能问题；




2、MySQL 为什么使用 B+ 树来作索引，对比 B 树它的优点和缺点是什么？
  * B树
    1. 1个m阶的B树具有如下几个特征：
      1. 根结点至少有两个子女。
      2. 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 <= k <= m
      3. 每一个叶子节点都包含k-1个元素，其中 m/2 <= k <= m
      4. 所有的叶子结点都位于同一层。
      5. 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。
    1. 多路搜索树，非二叉树
    2. 每个节点既保存索引，又保存数据
    3. 搜索时相当于二分查找
    4. 为什么设计成多路：
      * 降低树的高度，树的高度和查找的时间复杂度相关
    5. 可以设计成无限多路吗：
      * 不行，退化为有序数组
    6. 应用场景：文件系统、MongoDb索引
    7. 为什么用B树而不是红黑树或者有数数组呢：
      * 索引很大的情况下，内存不能将索引一次读完，需要磁盘IO操作，最坏情况下，磁盘IO操作次数等于索引树的高度，所以多路的B树会将树变得“矮胖”而减少磁盘IO
      * 在内存中红黑树是优于B树的
  * B+树
    1. 1个M阶的B+树具有如下几个特征：
      1. 有k个子树的中间节点包含有k个元素，每个元素不保存数据，只用来索引，所有数据保存在叶子节点
      2. 所有的叶子节点包含了全部元素的信息，及指向这些元素记录的指针，且叶子节点本身依关键字的大小自小而大顺序连接
      3. 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大或者最小元素
      4. 每个叶子节点都带有指向下一个节点的指针，形成了一个有序链表
    2. 多路搜索树，非二叉树
    3. 只有叶子节点保存数据
    4. 搜索时相当于二分查找
    5. 增加了相邻接点的指向指针。
    6. 应用场景：Mysql
    7. 为什么不用哈希表：
      * 哈希虽然能够提供 O(1) 的单数据行操作性能，但是对于范围查询和排序却无法很好地支持，最终导致全表扫描；
  * B+树优点：
    * B+树 对比 B树没有中间节点没有存数据，所以同样大小的磁盘页可以容纳更多的节点元素，同数据量下磁盘IO更少
    * B+树由于必须找到叶子节点，所以查找性能稳定，而B-树可能在中间节点，最优为O(1),最劣为O(logn)
    * 针对范围检索时，B树必须要做中序遍历，而B+树可以直接做O（n）的链表遍历
  * B树优点：
    * 因为B树节点中包含数据，经常访问的节点可以更靠近根节点，因为可以更快地访问
  * MySQL 为什么使用 B+ 树来作索引：
    * 硬盘的索引一般在磁盘上，数据量大的情况下无法一次性装入内存，B+树的设计允许数据分批加载，同时降低了树的高度，对比 B树没有中间节点没有存数据，所以同样大小的磁盘页可以容纳更多的节点元素，同数据量下磁盘IO更少。提高查找效率
    * 在数据库范围查询中,B+树索引有序，而且又有链表相连，B树必须要做中序遍历，而B+树可以直接做O（n）的链表遍历，速度很快。






 3、什么是数据库事务，MySQL 为什么会使用 InnoDB 作为默认选项
  * 数据库事务：多条语句作为一个整体进行操作的功能，可以确保该事务范围内的所有操作都可以全部成功或者全部失败
    * 特性：
      * A：Atomic，原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行；
      * C：Consistent，一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100；
      * I：Isolation，隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离；
      * D：Duration，持久性，即事务完成后，对数据库数据的修改被持久化存储。
    * 隐式事务：对于单条SQL语句，数据库系统自动将其作为一个事务执行
    * 显式事务：手动把多条SQL语句作为一个事务执行，使用BEGIN开启一个事务，使用COMMIT提交一个事务，这种事务被称为
    * ROLLBACK回滚事务
  * MySQL为什么会使用InnoDB作为默认选项：
    * InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高，但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，否则其他索引也会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。
    * InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败。
    * InnoDB 在 MySQL 5.6 之前不支持全文索引，而 MyISAM 一直都支持，如果你用的是老版本，查询效率上 MyISAM 要高。
    * InnoDB 锁粒度是行锁，而 MyISAM 是表锁。
    * InnoDB 支持事务，MyISAM 不支持，对于 InnoDB 每一条 SQL 语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条 SQL 语言放在 begin 和 commit 之间，组成一个事务。
    * InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快，但如果上述语句还包含了 where 子句，那么两者执行效率是一样的。
  * 如何选择：
    * 是否要支持事务，如果要请选择 Innodb，如果不需要可以考虑 MyISAM。
    * 如果表中绝大多数都是读查询（有人总结出 读:写比率大于100:1），可以考虑 MyISAM，如果既有读又有写，而且也挺频繁，请使用 InnoDB。
    * 系统崩溃后，MyISAM 恢复起来更困难，能否接受。


4、数据库的事务隔离级别有哪些？各有哪些优缺点？
  * 读未提交RAED UNCOMMITED：使用查询语句不会加锁，可能会读到未提交的行（Dirty Read）；
  * 读已提交READ COMMITED：只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read）
  * 可重复读REPEATABLE READ：多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能发生幻读（Phantom Read）；
  * 串行化SERIALIZABLE：InnoDB 隐式地将全部的查询语句加上共享锁，解决了幻读的问题；




MySQL 中默认的事务隔离级别就是 REPEATABLE READ，但是它通过 Next-Key 锁也能够在某种程度上解决幻读的问题。


几种锁：
  * 共享锁（读锁）：允许事务对一条行数据进行读取
  * 互斥锁（写锁）：允许事务对一条行数据进行删除或更新
  * 锁的粒度：
    * 行锁
    * 表锁：
      * 意向锁 ：是否有人请求锁定表中的某一行数据。
        * 意向共享锁：事务想要在获得表中某些记录的共享锁，需要在表上先加意向共享锁；
        * 意向互斥锁：事务想要在获得表中某些记录的互斥锁，需要在表上先加意向互斥锁；




锁的算法：
  * 记录锁（Record Lock）是加到索引记录上的锁
  * 间隙锁 (Gap Lock)是对索引记录中的一段连续区域的锁；当使用类似 SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE; 的 SQL 语句时，就会阻止其他事务向表中插入 id = 15 的记录，因为整个范围都被间隙锁锁定了,它唯一阻止的就是其他事务向这个范围中添加新的记录。


脏读、幻读、不可重复读
  * 脏读：在一个事务中，读取了其他事务未提交的数据。
  * 不可重复读：在一个事务中，同一行记录被访问了两次却得到了不同的结果。原因是在 READ COMMITED 的隔离级别下，存储引擎不会在查询记录时添加行锁，锁定 id = 3 这条记录
  * 幻读：在一个事务中，同一个范围内的记录被读取时，其他事务向这个范围添加了新的记录。可由更高的隔离级别 SERIALIZABLE 解决的，但是它也可以通过 MySQL 提供的 Next-Key锁解决




5、什么情况下会发生死锁，如何解决死锁？
6、简述脏读和幻读的发生场景，InnoDB 是如何解决幻读的？
  * 脏读： 在一个事务中，读取了其他事务未提交的数据。
    * 场景：当事务的隔离级别为 READ UNCOMMITED 时，我们在 SESSION 2 中插入的未提交数据在 SESSION 1 中是可以访问的。
    * 解决：提高事务隔离级别 READ COMMITED
    * 原因：在RAED UNCOMMITED事务隔离级别中，使用查询语句不会加锁




| SESSION 1| SESSION 2
---|---|---
| BEGING| BEGING
 |	id	|+-------+| SELECT * FROM test|
| | INSERT INTO test VALUES(1)
 |	id	|+	1	+| SELECT * FROM test|
  * 不可重复读： 在一个事务中，同一行记录被访问了两次却得到了不同的结果。
    * 场景：当事务的隔离级别为 READ COMMITED 时在 SESSION 1 先查询了一行数据，在这之后 SESSION 2 中修改了同一行数据并且提交了修改，在这时，如果 SESSION 1 中再次使用相同的查询语句，就会发现两次查询的结果不一样。
    * 解决：提高事务的隔离级别
    * 原因：原因就是，在 READ COMMITED 的隔离级别下，存储引擎不会在查询记录时添加行锁，锁定 id = 3 这条记录。

| SESSION 1| SESSION 2
---|---|---
| BEGING| BEGING
 |	id   |  v  |+	3   |  2  |+| SELECT * FROM test WHERE id = 3|
| | UPDATE test set v = 3 WHERE id = 3
| | COMMIT
 |	id   |  v  |+	3   |  3  |+| SELECT * FROM test WHERE id = 3|






  * 幻读： 在一个事务中，同一个范围内的记录被读取时，其他事务向这个范围添加了新的记录。
    * 场景: 重新开启了两个会话 SESSION 1 和 SESSION 2，在 SESSION 1 中我们查询全表的信息，没有得到任何记录；在 SESSION 2 中向表中插入一条数据并提交；由于 REPEATABLE READ 的原因，再次查询全表的数据时，我们获得到的仍然是空集, 但是在向表中插入同样的数据却出现了错误。
    * 解决: 幻读是由更高的隔离级别 SERIALIZABLE 解决的，但是它也可以通过 MySQL 提供的 Next-Key 锁解决
    * 原因 :REPEATABLE READ 和 READ UNCOMMITED 其实是矛盾的，如果保证了前者就看不到已经提交的事务，如果保证了后者，就会导致两次查询的结果不同，MySQL 为我们提供了一种折中的方式，能够在 REPEATABLE READ 模式下加锁访问已经提交的数据，其本身并不能解决幻读的问题，而是通过文章前面提到的 Next-Key 锁来解决

| SESSION 1| SESSION 2
---|---|---
| BEGING| BEGING
 |	id	|+-------+| SELECT * FROM test|
| | INSERT INTO test VALUES(1)
| | COMMIT
 |	id	|+	1	+| SELECT * FROM test|
| INSERT INTO test VALUES(1)|
| Dunlicate entry '1' for  'id'|
  * InnoDB 是如何解决幻读的 : 幻读是由更高的隔离级别 SERIALIZABLE 解决的，但是它也可以通过 MySQL 提供的 Next-Key 锁解决
  * Next-Key: Next-Key 锁锁定的是当前值和前面的范围
    * 举例：
      * 当我们更新一条记录，比如 SELECT * FROM users WHERE age = 30 FOR UPDATE;，InnoDB 不仅会在范围 (21, 30] 上加 Next-Key 锁，还会在这条记录后面的范围 (30, 40] 加间隙锁，所以插入 (21, 40] 范围内的记录都会被锁定








7、简述数据库中的 ACID 分别是什么？
  * A：Atomic，原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行；
  * C：Consistent，一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100；
  * I：Isolation，隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离；
  * D：Duration，持久性，即事务完成后，对数据库数据的修改被持久化存储。




8、并发事务会引发哪些问题？如何解决？
  * 脏读
    * 解决：提高事务隔离级别 READ COMMITED
  * 幻读
    * 解决: 幻读是由更高的隔离级别 SERIALIZABLE 解决的，但是它也可以通过 MySQL 提供的 Next-Key 锁解决
  * 不可重复读
    * 解决：提高事务的隔离级别
  * （具体见第六题）


 9、简述 Redis 持久化中 rdb 以及 aof 方案的优缺点
  * RDB：快照形式是直接把内存中的数据保存到一个 dump 文件中，定时保存，保存策略。Redis默认是快照RDB的持久化方式
  * AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。、
  * 当 Redis 重启时，它会优先使用 AOF 文件来还原数据集，因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。




RDB持久化：
  * 工作原理：当 Redis 需要做持久化时，Redis 会 fork 一个子进程，子进程将数据写到磁盘上一个临时 RDB 文件中。当子进程完成写临时文件后，将原来的 RDB 替换掉，这样的好处就是可以 copy-on-write。
  * Redis.conf配置

```
save 900 1 # 900秒之内，如果超过1个key被修改，则发起快照保存
save 300 10 # 300秒内，如果超过10个key被修改，则发起快照保存
save 60 10000 # 1分钟之内，如果1万个key被修改，则发起快照保存
```
  * 优点：
    * 这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB 非常适用于灾难恢复（disaster recovery）。
    * 灵活设置备份的频率和周期
    * 性能最大化：对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行 IO 操作了。也就是说，RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能
    * 恢复更快速：相比于 AOF 机制，RDB 的恢复速度更更快，更适合恢复数据，特别是在数据集非常大的情况。
  * 缺点：
    * 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。
    * RDB备份机制，是通过一个fork子进程来进行协助数据的持久化，在持久化的过程中，将会暂停所有的redis的数据集的操作，如果redis的数据集庞大，那么将有可能导致redis停止对外服务几百毫秒，或者是1秒




AOF 持久化：
  * 工作原理：使用 AOF 做持久化，每一个写命令都通过write函数追加到 appendonly.aof 中
  * Redis.conf配置

```
appendfsync yes
appendfsync always     #每次有数据修改发生时都会写入AOF文件。
appendfsync everysec   #每秒钟同步一次，该策略为AOF的缺省策略。
```
  * 优点：
    * 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。
    * AOF是基于日志模式记录数据操作，所以该操作可以更加好的保证数据的安全性。
    * AOF日志写入记录操作模式为 append 模式，所以在使用过程中，即使服务器出现的宕机情况，也不会破坏redis 的日志文件内容。
    * AOF 包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作
  * 缺点：
    * 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）
    * 针对相同数据量大小的恢复数据操作，建议使用RDB恢复，因相同数据大小情况下，RDB恢复速度比AOF恢复更快。
    * 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB 。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和 RDB 一样高效。




两者的区别：
  * RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。
  * AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。




Redis 为什么在使用 RDB 进行快照时会通过子进程的方式进行实现？
  1. 通过 fork 创建的子进程能够获得和父进程完全相同的内存空间，父进程对内存的修改对于子进程是不可见的，两者不会相互影响；
  2. 通过 fork 创建子进程时不会立刻触发大量内存的拷贝，内存在被修改时会以页为单位进行拷贝，这也就避免了大量拷贝内存而带来的性能问题；




10、简述 Redis 的哨兵机制
在 Redis 中，实现 高可用 的技术主要包括 持久化、复制、哨兵 和 集群，下面简单说明它们的作用，以及解决了什么样的问题：
  * 持久化：持久化是 最简单的 高可用方法。它的主要作用是 数据备份，即将数据存储在 硬盘，保证数据不会因进程退出而丢失。
  * 复制：复制是高可用 Redis 的基础，哨兵 和 集群 都是在 复制基础 上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制。
  * 哨兵：在复制的基础上，哨兵实现了 自动化 的 故障恢复。缺陷是 写操作 无法 负载均衡，存储能力 受到 单机 的限制。
  * 集群：通过集群，Redis 解决了 写操作 无法 负载均衡 以及 存储能力 受到 单机限制 的问题，实现了较为 完善 的 高可用方案。






Redis主从复制的问题
  1. 一旦 主节点宕机，从节点 作为 主节点 的 备份 可以随时顶上来。
  2. 扩展 主节点 的 读能力，分担主节点读压力。




主从复制 同时存在以下几个问题：
  1.  一旦 主节点宕机，从节点 晋升成 主节点，同时需要修改 应用方 的 主节点地址，还需要命令所有 从节点 去 复制 新的主节点，整个过程需要 人工干预。
  2. 主节点 的 写能力 受到 单机的限制。
  3. 主节点 的 存储能力 受到 单机的限制。
  4.  原生复制 的弊端在早期的版本中也会比较突出，比如：Redis 复制中断 后，从节点 会发起 psync。此时如果 同步不成功，则会进行 全量同步，主库 执行 全量备份 的同时，可能会造成毫秒或秒级的 卡顿。


基本工作原理：
我们可以将 Redis Sentinel 集群看成是一个 ZooKeeper 集群，它是集群高可用的心脏，它一般是由 3～5 个节点组成，这样挂了个别节点集群还可以正常运转。它负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户端。如此应用程序将无需重启即可自动完成节点切换。


Sentinel 的主要功能包括 主节点存活检测、主从运行情况检测、自动故障转移 （failover）、主从切换。Redis 的 Sentinel 最小配置是一主一从。
  * 监控:Sentinel 会不断的检查 主服务器 和 从服务器 是否正常运行。
  * 通知:当被监控的某个 Redis 服务器出现问题，Sentinel 通过 API 脚本 向 管理员 或者其他的 应用程序 发送通知。
  * 自动故障转移当 主节点 不能正常工作时，Sentinel 会开始一次 自动的 故障转移操作，它会将与 失效主节点 是 主从关系 的其中一个 从节点 升级为新的 主节点，并且将其他的 从节点 指向 新的主节点。
  * 配置提供者:在 Redis Sentinel 模式下，客户端应用 在初始化时连接的是 Sentinel 节点集合，从中获取 主节点 的信息。


主观下线和客观下线
默认情况下，每个 Sentinel 节点会以 每秒一次 的频率对 Redis 节点和 其它 的 Sentinel 节点发送 PING 命令，并通过节点的 回复 来判断节点是否在线。
  * 主观下线: 适用于所有 主节点 和 从节点。如果在 down-after-milliseconds 毫秒内，Sentinel 没有收到 目标节点 的有效回复，则会判定 该节点 为 主观下线。
  * 客观下线:只适用于 主节点。如果 主节点 出现故障，Sentinel 节点会通过 sentinel is-master-down-by-addr 命令，向其它 Sentinel 节点询问对该节点的 状态判断。如果超过 <quorum> 个数的节点判定 主节点 不可达，则该 Sentinel 节点会判断 主节点 为 客观下线。




Sentinel的通信命令
  * 连接其他哨兵：pub/sub
  * 连接redis：cmd


工作流程：
每个 Sentinel 节点都需要 定期执行 以下任务：
  1. 每个 Sentinel 以 每秒钟 一次的频率，向它所知的 主服务器、从服务器 以及其他 Sentinel 实例 发送一个 PING 命令。
  2. 如果一个 实例（instance）距离 最后一次 有效回复 PING 命令的时间超过 down-after-milliseconds 所指定的值，那么这个实例会被 Sentinel 标记为 主观下线。
  3. 如果一个 主服务器 被标记为 主观下线，那么正在 监视 这个 主服务器 的所有 Sentinel 节点，要以 每秒一次 的频率确认 主服务器 的确进入了 主观下线 状态。
  4. 如果一个 主服务器 被标记为 主观下线，并且有 足够数量 的 Sentinel（至少要达到 配置文件 指定的数量）在指定的 时间范围 内同意这一判断，那么这个 主服务器 被标记为 客观下线。
  5. 在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率，向它已知的所有 主服务器 和 从服务器 发送 INFO 命令。当一个 主服务器 被 Sentinel 标记为 客观下线 时，Sentinel 向 下线主服务器 的所有 从服务器 发送 INFO 命令的频率，会从 10 秒一次改为 每秒一次。
  6. Sentinel 和其他 Sentinel 协商 主节点 的状态，如果 主节点 处于 SDOWN 状态，则投票自动选出新的 主节点。将剩余的 从节点 指向 新的主节点 进行 数据复制。
  7. 当没有足够数量的 Sentinel 同意 主服务器 下线时， 主服务器 的 客观下线状态 就会被移除。当 主服务器 重新向 Sentinel 的 PING 命令返回 有效回复 时，主服务器 的 主观下线状态 就会被移除。




消息丢失：
Redis 主从采用异步复制，意味着当主节点挂掉时，从节点可能没有收到全部的同步消息，这部分未同步的消息就丢失了。如果主从延迟特别大，那么丢失的数据就可能会特别多。Sentinel 无法保证消息完全不丢失，但是也尽可能保证消息少丢失。它有两个选项可以限制主从延迟过大。
```
min-slaves-to-write 1
min-slaves-max-lag 10
```
第一个参数表示主节点必须至少有一个从节点在进行正常复制，否则就停止对外写服务，丧失可用性。
何为正常复制，何为异常复制？这个就是由第二个参数控制的，它的单位是秒，表示如果 10s 没有收到从节点的反馈，就意味着从节点同步不正常，要么网络断开了，要么一直没有给反馈。


11、Redis 如何实现分布式锁？
Redis 锁主要利用 Redis 的 setnx 命令。
  * 加锁命令：SETNX key value，当键不存在时，对键进行设置操作并返回成功，否则返回失败。KEY 是锁的唯一标识，一般按业务来决定命名。
  * 解锁命令：DEL key，通过删除键值对释放锁，以便其他线程可以通过 SETNX 命令来获取锁。
  * 锁超时：EXPIRE key timeout, 设置 key 的超时时间，以保证即使锁没有被显式释放，锁也可以在一定时间后自动释放，避免资源被永远锁住。


伪代码如下：
```
if (setnx(key, 1) == 1){
    expire(key, 30)
    try {
        //TODO 业务逻辑
    } finally {
        del(key)
    }
}
```


上面的方法存在一些问题，比如
  1. SETNX 和 EXPIRE 非原子性：如果 SETNX 成功，在设置锁超时时间后，服务器挂掉、重启或网络问题等，导致 EXPIRE 命令没有执行，锁没有设置超时时间变成死锁。
    * 解决办法：
      *  Redis 2.6.12以上版本为set指令增加了可选参数，伪代码如下：set（key，1，30，NX）
      * Lua脚本
  2. 锁误解除：如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。
    * 解决办法
      * 通过在 value 中设置当前线程加锁的标识，在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。可生成一个 UUID 标识当前线程、因为判断和释放锁是两个独立操作，不是原子性。所以这块使用lua脚本
      * 使用 lua 脚本做验证标识和解锁操作。
  3. 超时解锁导致并发：如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。
    * 解决办法：
      * 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
      * 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。
  4. 不可重入：当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败
    * 解决办法：
      * Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。在本地记录记录重入次数
  5. 无法等待锁释放：上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。
    * 解决办法：
      * *可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。
      * 另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息


12、简述 Redis 中如何防止缓存雪崩和缓存击穿

