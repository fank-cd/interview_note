# Mysql
读写锁：在处理并发读或者写时，可以通过实现一个由两种类型的锁组成的锁系统来解决问题
  * 读锁（共享锁）
    * 相互不干扰
    * 多个客户可以在同一时刻读取同一个资源
  * 写锁（排他锁）
    * 排他的
    * 一个写锁会阻塞其他的写锁和读锁




锁粒度：只对会修改的数据片进行精确的锁定，任何时候，在给定的资源上，锁的数据量越少，系统并发量越高
  * 表锁：MySQL中最基本的锁策略，并且开销最小。会锁定整张表
    * 并发程度低
    * 开销小
  * 行级锁
    * 最大程度支持并发处理
    * 最大的锁开销






* * *


数据库事务：多条语句作为一个整体进行操作的功能，可以确保该事务范围内的所有操作都可以全部成功或者全部失败
    * 特性：
      * A：Atomic，原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行；
      * C：Consistent，一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100；
      * I：Isolation，隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离；一个事务所做的修改在最终提交以前，对其他事务是不可见的。
      * D：Duration，持久性，即事务完成后，对数据库数据的修改被持久化存储。
    * 隐式事务：对于单条SQL语句，数据库系统自动将其作为一个事务执行
    * 显式事务：手动把多条SQL语句作为一个事务执行，使用BEGIN开启一个事务，使用COMMIT提交一个事务，这种事务被称为




* * *




隔离级别：较低级别的隔离通常可以执行更高的并发，系统的开销也更低。
  * 读未提交RAED UNCOMMITED：使用查询语句不会加锁，可能会读到未提交的行（Dirty Read）；
    * 脏读：在一个事务中，读取了其他事务未提交的数据。
      * 场景：当事务的隔离级别为 READ UNCOMMITED 时，我们在 SESSION 2 中插入的未提交数据在 SESSION 1 中是可以访问的。
      * 解决：提高事务隔离级别 READ COMMITED
      * 原因：在RAED UNCOMMITED事务隔离级别中，使用查询语句不会加锁
  * 读已提交READ COMMITED：只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read）
    * 不可重复读：不可重复读： 在一个事务中，同一行记录被访问了两次却得到了不同的结果。
      * 场景：当事务的隔离级别为 READ COMMITED 时在 SESSION 1 先查询了一行数据，在这之后 SESSION 2 中修改了同一行数据并且提交了修改，在这时，如果 SESSION 1 中再次使用相同的查询语句，就会发现两次查询的结果不一样。
      * 解决：提高事务的隔离级别
      * 原因：原因就是，在 READ COMMITED 的隔离级别下，存储引擎不会在查询记录时添加行锁，锁定 id = 3 这条记录。
  * 可重复读REPEATABLE READ：多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能发生幻读（Phantom Read）；
    * 幻读： 在一个事务中，同一个范围内的记录被读取时，其他事务向这个范围添加了新的记录。
      * 场景: 重新开启了两个会话 SESSION 1 和 SESSION 2，在 SESSION 1 中我们查询全表的信息，没有得到任何记录；在 SESSION 2 中向表中插入一条数据并提交；由于 REPEATABLE READ 的原因，再次查询全表的数据时，我们获得到的仍然是空集, 但是在向表中插入同样的数据却出现了错误。
      * 解决: 幻读是由更高的隔离级别 SERIALIZABLE 解决的，但是它也可以通过 MySQL 提供的 Next-Key 锁解决
      * 原因 :REPEATABLE READ 和 READ UNCOMMITED 其实是矛盾的，如果保证了前者就看不到已经提交的事务，如果保证了后者，就会导致两次查询的结果不同，MySQL 为我们提供了一种折中的方式，能够在 REPEATABLE READ 模式下加锁访问已经提交的数据，其本身并不能解决幻读的问题，而是通过文章前面提到的 Next-Key 锁来解决
  * 串行化SERIALIZABLE：InnoDB 隐式地将全部的查询语句加上共享锁，解决了幻读的问题，但可能会导致大量的超时和锁争用的问题，实际应用中很少用到这个级别的隔壁；
    * InnoDB 是如何解决幻读的 : 幻读是由更高的隔离级别 SERIALIZABLE 解决的，但是它也可以通过 MySQL 提供的 Next-Key 锁解决
    * Next-Key: Next-Key 锁锁定的是当前值和前面的范围
      * 举例：
        * 当我们更新一条记录，比如 SELECT * FROM users WHERE age = 30 FOR UPDATE;，InnoDB 不仅会在范围 (21, 30] 上加 Next-Key 锁，还会在这条记录后面的范围 (30, 40] 加间隙锁，所以插入 (21, 40] 范围内的记录都会被锁定




脏读：
| SESSION 1| SESSION 2
---|---|---
| BEGING| BEGING
 |	id	|+-------+| SELECT * FROM test|
| | INSERT INTO test VALUES(1)
 |	id	|+	1	+| SELECT * FROM test|
不可重复读
| SESSION 1| SESSION 2
---|---|---
| BEGING| BEGING
 |	id   |  v  |+	3   |  2  |+| SELECT * FROM test WHERE id = 3|
| | UPDATE test set v = 3 WHERE id = 3
| | COMMIT
 |	id   |  v  |+	3   |  3  |+| SELECT * FROM test WHERE id = 3|


幻读
| SESSION 1| SESSION 2
---|---|---
| BEGING| BEGING
 |	id	|+-------+| SELECT * FROM test|
| | INSERT INTO test VALUES(1)
| | COMMIT
 |	id	|+	1	+| SELECT * FROM test|
| INSERT INTO test VALUES(1)|
| Dunlicate entry '1' for  'id'|




* * *




死锁：死锁是指两个或者多个事务在同一个资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。
  * 资源：大部分的死锁都和资源有关，在进程对设备、文件具有独占性（排他性）时会产生死锁。我们把这类需要排他性使用的对象称为资源(resource)。资源主要分为 可抢占资源和不可抢占资源
  * 可抢占资源和不可抢占资源:
    * 可抢占资源(preemptable resource) 可以从拥有它的进程中抢占而不会造成其他影响，内存就是一种可抢占性资源，任何进程都能够抢先获得内存的使用权。
    * 不可抢占资源(nonpreemtable resource) 指的是除非引起错误或者异常，否则进程无法抢占指定资源，这种不可抢占的资源比如有打印机，在进程执行调度的过程中，其他进程是不能得到该资源的
  * 死锁的概念：是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。
  * 死锁产生的原因：
    * 竞争可消耗资源引起死锁:系统资源在分配时出现失误,进程间对资源的相互争夺而造成僵局.
    * 进程推进顺序不当引起死锁 :多道程序运行时,进程推进顺序不合理
  * 产生死锁的必要条件：
    * 互斥条件：一个资源每次只能被一个进程使用。
    * 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
    * 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
    * 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。
  * 死锁的预防  ：死锁的预防是保证系统不进入死锁状态的一种策略。它的基本思想是要求进程申请资源时遵循某种协议，从而打破产生死锁的四个必要条件中的一个或几个，保证系统不会进入死锁状态。
    * 破坏互斥条件。即允许进程同时访问某些资源。但是，有的资源是不允许被同时访问的，像打印机等等，这是由资源本身的属性所决定的。所以，这种办法并无实用价值。
    * 破坏不可剥夺条件。即允许进程强行从占有者那里夺取某些资源。就是说，当一个进程已占有了某些资源，它又申请新的资源，但不能立即被满足时，它必须释放所占有的全部资源，以后再重新申请。它所释放的资源可以分配给其它进程。这就相当于该进程占有的资源被隐蔽地强占了。这种预防死锁的方法实现起来困难，会降低系统性能
    * 破坏请求与保持条件。可以实行资源预先分配策略。即进程在运行前一次性地向系统申请它所需要的全部资源。如果某个进程所需的全部资源得不到满足，则不分配任何资源，此进程暂不运行。只有当系统能够满足当前进程的全部资源需求时，才一次性地将所申请的资源全部分配给该进程。由于运行的进程已占有了它所需的全部资源，所以不会发生占有资源又申请资源的现象，因此不会发生死锁。
      * 缺点：
        * 在许多情况下，一个进程在执行之前不可能知道它所需要的全部资源。这是由于进程在执行时是动态的，不可预测的
        * 资源利用率低。无论所分资源何时用到，一个进程只有在占有所需的全部资源后才能执行。即使有些资源最后才被该进程用到一次，但该进程在生存期间却一直占有它们，造成长期占着不用的状况。这显然是一种极大的资源浪费
        * 降低了进程的并发性。因为资源有限，又加上存在浪费，能分配到所需全部资源的进程个数就必然少了
    * 破坏循环等待条件，实行资源有序分配策略。采用这种策略，即把资源事先分类编号，按号分配，使进程在申请，占用资源时不会形成环路。所有进程对资源的请求必须严格按资源序号递增的顺序提出。进程占用了小号资源，才能申请大号资源，就不会产生环路，从而预防了死锁。这种策略与前面的策略相比，资源的利用率和系统吞吐量都有很大提高
      * 缺点：
        * 限制了进程对资源的请求，同时给系统中所有资源合理编号也是件困难事，并增加了系统开销
        * 为了遵循按编号申请的次序，暂不使用的资源也需要提前申请，从而增加了进程对资源的占用时间
  * 死锁的避免：
    * 安全序列：  我们首先引入安全序列的定义：所谓系统是安全的，是指系统中的所有进程能够按照某一种次序分配资源，并且依次地运行完毕，这种进程序列{P1，P2，...，Pn}就是安全序列。如果存在这样一个安全序列，则系统是安全的；如果系统不存在这样一个安全序列，则系统是不安全的
    * 安全序列{P1，P2，...，Pn}是这样组成的：若对于每一个进程Pi，它需要的附加资源可以被系统中当前可用资源加上所有进程Pj当前占有资源之和所满足，则{P1，P2，...，Pn}为一个安全序列，这时系统处于安全状态，不会进入死锁状态。
    * 银行家算法
  * 死锁的检测与恢复
    * 最简单，最常用的方法就是进行系统的重新启动，不过这种方法代价很大，它意味着在这之前所有的进程已经完成的计算工作都将付之东流，包括参与死锁的那些进程，以及未参与死锁的进程。
    * 撤消进程，剥夺资源。终止参与死锁的进程，收回它们占有的资源，从而解除死锁。这时又分两种情况：一次性撤消参与死锁的全部进程，剥夺全部资源；或者逐步撤消参与死锁的进程，逐步收回死锁进程占有的资源。一般来说，选择逐步撤消的进程时要按照一定的原则进行，目的是撤消那些代价最小的进程，比如按进程的优先级确定进程的代价；考虑进程运行时的代价和与此进程相关的外部作业的代价等因素。
    * 进程回退策略，即让参与死锁的进程回退到没有发生死锁前某一点处，并由此点处继续执行，以求再次执行时不再发生死锁。虽然这是个较理想的办法，但是操作起来系统开销极大，要有堆栈这样的机构记录进程的每一步变化，以便今后的回退，有时这是无法做到的。
    * 看门狗计数器:当线程正常运行的时候会每隔一段时间重置计数器，在没有发生死锁的情况下，一切都正常进行。一旦发生死锁，由于无法重置计数器导致定时器超时，这时程序会通过重启自身恢复到正常状态。
  * 数据库中的死锁：
    * 一般原因：
      * 多个事务试图以不同顺序锁定资源
      * 多个事务同时锁定同一个资源
    * 死锁检测和死锁超时：一般来说，越复杂的系统，越能检测到死锁的循环依赖。并立即返回一个错误
      * 查询超时时放弃锁请求（这种方式通常来说不太好）
      * InnoDB：将持有最少行级排他锁的事务进行回滚




死锁事务：
```
事务1
    START TRANSACTIION;
    UPDATE StockPrice SET close = 45.50 WHERE stock_id = 4 and date = "2002-5-0-1";
    UPDATE StockPrice SET close = 19.80 WHERE stock_id =3 and date = "2002-5-0-2";
	COMMIT;


事务2
    START TRANSACTIION;
    UPDATE StockPrice SET close = 20.12 WHERE stock_id =3 and date = "2002-5-0-2";
    UPDATE StockPrice SET close = 47.20 WHERE stock_id = 4 and date = "2002-5-0-1";
    COMMIT;




```


死锁代码：
```
"""
死锁代码
要AB两个锁
当A锁内部需要使用B锁，同时B锁内部需要使用A锁的时候，就要可能会出现死锁
出现死所的解决方法：
1.重构代码
2.添加timeout时间
下面代码中要可能返回下面内容，在同时认为锁被对方占用，同时释放
Thread-1获取到a锁
Thread-2获取到b锁
over
"""
import time
from threading import Thread, Lock




lock_a = Lock()
lock_b = Lock()




class MyThread(Thread):
    def run(self) -> None:
        if lock_a.acquire():  # 如果a锁可以获取到，返回True,获取不到就阻塞
            print(self.name + "获取到a锁")
            time.sleep(0.1)
            # if lock_b.acquire(timeout=0.01):  # 这里不加退出时间就会要可能出现死锁
            if lock_b.acquire():  # 这里不加退出时间就会要可能出现死锁
                print(self.name + "获取到b锁，现有ab锁")
                lock_b.release()
            lock_a.release()


class MyThread1(Thread):
    def run(self) -> None:
        if lock_b.acquire():  # 如果b锁可以获取到，返回True,获取不到就阻塞
            print(self.name + "获取到b锁")
            time.sleep(0.1)
            if lock_b.acquire():  # 这里不加退出时间就会要可能出现死锁
                print(self.name + "获取到a锁，现有ab锁")
                lock_a.release()
            lock_b.release()


if __name__ == '__main__':
    t1 = MyThread()
    t2 = MyThread1()
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    print("over")
```




* * *




  * 乐观锁和悲观锁其实都是并发控制的机制，同时它们在原理上就有着本质的差别；
    * 乐观锁是一种思想，它其实并不是一种真正的『锁』，它会先尝试对资源进行修改，在写回时判断资源是否进行了改变，如果没有发生改变就会写回，否则就会进行重试，在整个的执行过程中其实都没有对数据库进行加锁；
    * 悲观锁就是一种真正的锁了，它会在获取资源前对资源进行加锁，确保同一时刻只有有限的线程能够访问该资源，其他想要尝试获取资源的操作都会进入等待状态，直到该线程完成了对资源的操作并且释放了锁后，其他线程才能重新操作资源；
  * 乐观锁不会存在死锁的问题，但是由于更新后验证，所以当冲突频率和重试成本较高时更推荐使用悲观锁
  * 而需要非常高的响应速度并且并发量非常大的时候使用乐观锁就能较好的解决问题，在这时使用悲观锁就可能出现严重的性能问题；




* * *
MVCC（多版本 并发控制）
  * MVCC实现：
    * 通过保存数据在某个时间点的快照，不管需要执行多长时间，每个事务能看到的数据都是一样的。
    * 根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。
  * 分为乐观并发控制和悲观并发控制
  * 当前读和快照读
    * 当前读: 像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁
    * 快照读:像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本
  * MVCC能解决的问题：
    * 数据库并发场景：
      * 读-读：不存在任何问题，也不需要并发控制
      * 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
      * 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失
    * 解决的问题：
      * 解决读-写冲突的无锁并发控制
        * 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能
        * 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题
    * 如何解决的：
      * 为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。
  * 实现原理：
    * 3个隐式字段 ：每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段
      * DB_TRX_ID：6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID
      * DB_ROLL_PTR：7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）
      * DB_ROW_ID：6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引


例:
name|
age
| DB_ROW_ID(隐式主键| DB_TRX_ID（事务id）| DB_ROLL_PTR（回滚指针）
---|---|---|---|---
TOM| 30| 1| 2| 0x12446123（指向事务1）




  * undo日志
    * insert undo log :代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃
    * update undo log: 事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除
    *  流程：
      1. 比如一个有个事务插入persion表插入了一条新记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL
      2. 现在来了一个事务1对该记录的name做出了修改，改为Tom
        * 在事务1修改该行(记录)数据时，数据库会先对该行加排他锁
        * 然后把该行数据拷贝到undo log中，作为旧记录，既在undo log中有当前行的拷贝副本
        * 拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示我的上一个版本就是它
        * 事务提交后，释放锁
      3. 又来了个事务2修改person表的同一个记录，将age修改为30岁
        * 在事务2修改该行数据时，数据库也先为该行加锁
        * 然后把该行数据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的undo log最前面
        * 修改该行age为30岁，并且修改隐藏字段的事务ID为当前事务2的ID, 那就是2，回滚指针指向刚刚拷贝到undo log的副本记录
        * 事务提交，释放锁


例
name|
age
| DB_ROW_ID(隐式主键| DB_TRX_ID（事务id）| DB_ROLL_PTR（回滚指针）
---|---|---|---|---
TOM| 24| 1| 1| 0x12446545（指向最初数据）


name|
age
| DB_ROW_ID(隐式主键| DB_TRX_ID（事务id）| DB_ROLL_PTR（回滚指针）
---|---|---|---|---
jerry| 24| 1| null| null




  * Read View：Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)
    * 作用： Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。
    * 实现：Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本
    * 4个属性
      * trx_ids: 当前系统活跃(未提交)事务版本号集合
      * low_limit_id: 创建当前read view 时“当前系统最大事务版本号+1”
      * up_limit_id: 创建当前read view 时“系统正处于活跃事务最小版本号”
      * creator_trx_id: 创建当前read view的事务版本号
    * 判断条件：
      * 首先比较DB_TRX_ID < up_limit_id, 如果小于，则当前事务能看到DB_TRX_ID 所在的记录，如果大于等于进入下一个判断
      * 接下来判断 DB_TRX_ID>= low_limit_id , 如果大于等于则代表DB_TRX_ID 所在的记录在Read View生成后才出现的，那对当前事务肯定不可见，如果小于则进入下一个判断
      * 判断DB_TRX_ID 是否在活跃事务之中，，如果在，则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的；如果不在，则说明，你这个事务在Read View生成之前就已经Commit了，你修改的结果，我当前事务是能看见的
  * InnoDbMVCC 简单示意
    * SELECT
      * InnoDB会根据以下两个条件检查每行记录：
        * InnoDB只查找早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的
        * 行的删除版本要么未定义，要么大于当前事务版本的行。这样可以确保事务读取到的行，在事务开始之前未被删除
      * 符合条件的才会返回作为查询结果
    *  INSERT
      * InnoDb为新插入的每一行保存当前系统版本号作为行版本号
    * DELETE
      * InnoDB为删除的每一行保存当前系统版本号作为行删除标识
    * UPDATE
      * InnoDB为插入一行新纪录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识




  * 优点：
    * 使读数据操作简单
    * 性能提高
    * 解决不可重复读和脏读
  * 缺点：
    * 需要额外空间
  * MVCC工作的隔离级别：
    * 可重复读
    * 读已提交
  * MVCC不支持的隔离级别：
    * 读未提交：总是读取最新的数据行
    * 序列化：会对所有读取的行加锁






MySQL索引数据结构


  * B树和B+树
    1. B树
      1. 1个m阶的B树具有如下几个特征：
        1. 根结点至少有两个子女。
        2. 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 <= k <= m
        3. 每一个叶子节点都包含k-1个元素，其中 m/2 <= k <= m
        4. 所有的叶子结点都位于同一层。
        5. 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。
      1. 多路搜索树，非二叉树
      2. 每个节点既保存索引，又保存数据
      3. 搜索时相当于二分查找
      * 为什么设计成多路：
        * 降低树的高度，树的高度和查找的时间复杂度相关
      * 可以设计成无限多路吗：
        * 不行，退化为有序数组
      * 应用场景：文件系统、MongoDb索引
      * 为什么用B树而不是红黑树或者有数数组呢：
        * 索引很大的情况下，内存不能将索引一次读完，需要磁盘IO操作，最坏情况下，磁盘IO操作次数等于索引树的高度，所以多路的B树会将树变得“矮胖”而减少磁盘IO
        * 在内存中红黑树是优于B树的
    1. B+树
      1. 1个M阶的B+树具有如下几个特征：
        1. 有k个子树的中间节点包含有k个元素，每个元素不保存数据，只用来索引，所有数据保存在叶子节点
        2. 所有的叶子节点包含了全部元素的信息，及指向这些元素记录的指针，且叶子节点本身依关键字的大小自小而大顺序连接
        3. 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大或者最小元素
        4. 每个叶子节点都带有指向下一个节点的指针，形成了一个有序链表
      2. 多路搜索树，非二叉树
      3. 只有叶子节点保存数据
      4. 搜索时相当于二分查找
      5. 增加了相邻接点的指向指针。
      6. 应用场景：Mysql
      * 为什么不用哈希表：
        * 哈希虽然能够提供 O(1) 的单数据行操作性能，但是对于范围查询和排序却无法很好地支持，最终导致全表扫描；
  * B+树优点：
    * B+树 对比 B树没有中间节点没有存数据，所以同样大小的磁盘页可以容纳更多的节点元素，同数据量下磁盘IO更少
    * B+树由于必须找到叶子节点，所以查找性能稳定，而B-树可能在中间节点，最优为O(1),最劣为O(logn)
    * 针对范围检索时，B树必须要做中序遍历，而B+树可以直接做O（n）的链表遍历
  * B树优点：
    * 因为B树节点中包含数据，经常访问的节点可以更靠近根节点，因为可以更快地访问
  * MySQL 为什么使用 B+ 树来作索引：
    * 硬盘的索引一般在磁盘上，数据量大的情况下无法一次性装入内存，B+树的设计允许数据分批加载，同时降低了树的高度，对比 B树没有中间节点没有存数据，所以同样大小的磁盘页可以容纳更多的节点元素，同数据量下磁盘IO更少。提高查找效率
    * 在数据库范围查询中,B+树索引有序，而且又有链表相连，B树必须要做中序遍历，而B+树可以直接做O（n）的链表遍历，速度很快。




Mysql存储引擎，InnoDB和MyISAM
  * InnoDB：
    * 支持事务
    * 支持外键
    * InnoDB是聚簇索引，聚簇索引的文件存放在主键索引的叶子节点上
    * 锁的最小粒度是行锁
  * MyISAM
    * 不支持事务
    * 不支持外键
    * MyISAM不是，数据文件是分离的
    *  锁的最小粒度是表
  * 默认搜索引擎：Mysql5.1之前默认MyISAM,之后为InnoDB






varchar 和 char 的区别
  * char是指:使用指定长度的固定长度表示字符串的一种字段类型；比如char（8），则数据库会使用固定的1个字节(八位）来存储数据，不足8位的字符串在其后补空字符。
  * varchar(M)是一种比char更加灵活的数据类型，同样用于表示字符数据，但是varchar可以保存可变长度的字符串。其中M代表该数据类型所允许保存的字符串的最大长度，只要长度小于该最大值的字符串都可以被保存在该数据类型中。因此，对于那些难以估计确切长度的数据对象来说，使用varchar数据类型更加明智。MySQL4.1以前,varchar数据类型所支持的最大长度255,5.0以上版本支持65535字节长度,utf8编码下最多支持21843个字符(不为空)
  * char：定长，效率高，一般用于固定长度的表单提交数据存储；例如：身份证号，手机号，电话，密码等。
  * varchar：不定长，效率偏低。




MySQL 三种日志
  * binlog：binlog用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。binlog是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录binlog日志。
    * 逻辑日志：可以简单理解为记录的就是sql语句。
    * binlog使用场景
      1.  主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。
      2.  数据恢复：通过使用mysqlbinlog工具来恢复数据。
    * binlog刷盘时机：对于InnoDB存储引擎而言，只有在事务提交时才会记录biglog，mysql通过sync_binlog参数控制biglog的刷盘时机，取值范围是0-N：
      * 0：不去强制要求，由系统自行判断何时写入磁盘；
      * 1：每次commit的时候都要将binlog写入磁盘；
      * N：每N个事务，才会将binlog写入磁盘。
      * 从上面可以看出，sync_binlog最安全的是设置是1，这也是MySQL 5.7.7之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。
  * redo log：事务的四大特性里面有一个是持久性，具体来说就是只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态，而redo log，具体来说就是只记录事务对数据页做了哪些修改
    * redo log包括两部分：
      * 内存中的日志缓冲(redo log buffer)
      * 磁盘上的日志文件(redo log file)。
    * mysql每执行一条DML语句，先将记录写入redo log buffer，后续某个时间点再一次性将多个操作记录写到redo log file。这种先写日志，再写磁盘的技术就是MySQL里经常说到的WAL(Write-Ahead Logging) 技术。
    * 在计算机操作系统中，用户空间(user space)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间(kernel space)缓冲区(OS Buffer)。因此，redo log buffer写入redo log file实际上是先写入OS Buffer，然后再通过系统调用fsync()将其刷到redo log
    * mysql支持三种将redo log buffer写入redo log file的时机，可以通过innodb_flush_log_at_trx_commit参数配置，各参数值含义如下：
      * 0（延迟写）事务提交时不会将redo log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到redo log file中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。
      * 1（实时写，实时刷）事务每次提交都会将redo log buffer中的日志写入os buffer并调用fsync()刷到redo log file中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。
      * 2（实时写，延迟刷）每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到redo log file。

| redo log| binlog
---|---|---
文件大小| redo log的大小是固定的。| binlog可通过配置参数max_binlog_size设置每个binlog文件的大小。
实现方式| redo log是InnoDB引擎层实现的，并不是所有引擎都有。| binlog是Server层实现的，所有引擎都可以使用 binlog日志
记录方式| redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。| binlog 通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上
适用场景| redo log适用于崩溃恢复(crash-safe)| binlog适用于主从复制和数据恢复


  * undo log：数据库事务四大特性中有一个是原子性，具体来说就是 原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况。实际上，原子性底层就是通过undo log实现的
    * insert undo log :代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃
    * update undo log: 事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除
    *  流程：
      * 比如一个有个事务插入persion表插入了一条新记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL
      * 现在来了一个事务1对该记录的name做出了修改，改为Tom
        1. 在事务1修改该行(记录)数据时，数据库会先对该行加排他锁
        2. 然后把该行数据拷贝到undo log中，作为旧记录，既在undo log中有当前行的拷贝副本
        3. 拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示我的上一个版本就是它
        4. 事务提交后，释放锁
      * 又来了个事务2修改person表的同一个记录，将age修改为30岁
        1. 在事务2修改该行数据时，数据库也先为该行加锁
        2. 然后把该行数据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的undo log最前面
        3. 修改该行age为30岁，并且修改隐藏字段的事务ID为当前事务2的ID, 那就是2，回滚指针指向刚刚拷贝到undo log的副本记录
        4. 事务提交，释放锁





---
### NOTE ATTRIBUTES
>Created Date: 2021-03-06 17:29:09
>Last Evernote Update Date: 2021-03-12 16:35:30
>author: 一的平方
>source: desktop.win
>source-application: yinxiang.win32